Notationï¼š



![image-20250218143507603](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250218143507603.png)

![img](https://i-blog.csdnimg.cn/blog_migrate/bfe82881bbbcf5512ee96c38a7f0de43.png)

Dä¸ªä¸åŒçš„featureå¯¹åº”ä¸€ä¸ªlabel y

 Step1:

trainingâ€“ Given:labeled training dataset

â€“ Goal:learn a classifier from the  training dataset â€¢

 Step2:

predictionâ€“ Given:unlabeled test dataset : learned classifier

â€“ Goal:predict a label for each  instance â€¢ 

Step3:

evaluationâ€“ Given:predictions from Step II : labeled test dataset

â€“ Goal:compute the test error  rate (i.e. error rate on the test  dataset)

evaluation:

![image-20250218143912583](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250218143912583.png)

error rateï¼šè®¡ç®—å‡ºæ¥ä¸ç›¸ç­‰çš„æ—¶å€™ã€‚



classifierï¼š

![image-20250220132553129](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250220132553129.png)

- majority voteï¼šåªé¢„æµ‹ç»“æœä¸ºtrain setä¸­æœ€å¤šæ¬¡å‡ºç°çš„ç»“æœ
- memorizerï¼šå¦‚æœå‡ºç°äº†ä¸è®­ç»ƒé›†ä¸­ç›¸åŒçš„featureé‚£ä¹ˆæ ¹æ®ä»–å¯¹åº”çš„labelæ¥é¢„æµ‹å¦åˆ™é‡‡ç”¨1.æ‰€ä»¥å¯¹äºtrain erroræ˜¯0.
- decision stumpsï¼šbased on a single feature,ğ‘¥ğ‘‘,predict the most common label in the training dataset among all   data points that have the same value for ğ‘¥d

# decision treeï¼š![image-20250220160419169](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250220160419169.png)

å¦‚ä½•é€‰æ‹©splitting featureï¼š

- min error rate

- max mutual information:

  > entrophy:ä»£è¡¨äº†äº‹ä»¶çš„ä¸ç¡®å®šæ€§ã€‚![image-20250220160617209](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250220160617209.png)

  ![image-20250220160703681](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250220160703681.png)

å¦‚ä½•é€‰æ‹©splitting featureçš„é¡ºåºï¼š

![image-20250220160836049](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250220160836049.png)

æ¯ä¸€ä¸ªsplitting featureéƒ½éµå¾ªè¿™ä¸ªåŸåˆ™ï¼Œæ‰¾æœ€å¤§çš„mutual informationï¼Œé€’å½’ç®—æ³•ã€‚

ä»€ä¹ˆæ—¶å€™ç»“æŸï¼š![image-20250225223427523](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250225223427523.png)

é™åˆ¶æ ‘çš„æ·±åº¦å’Œè®¾ç½®thresholdæ˜¯ä¸ºäº†é¿å…overfitã€‚

overfitï¼štrue error>train error

train accuracyåœ¨å¢åŠ ï¼Œè€Œvalidation accuracyåœ¨é™ä½ã€‚![image-20250220160211701](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250220160211701.png)



given a decision tree,how to decide it is the best one?

remove every node (using majority vote (according to **training data set**))to decide it's result label)and compute the final error rate,if we can find a better rate, then it is not the best decision tree.When  to stop? Cut every point and an not be better.



Duck Test:

æŠŠä¸€ä¸ªç‚¹åˆ†ç±»åˆ°ç¦»ä»–æœ€è¿‘çš„ç‚¹çš„ç§ç±»ï¼š

1. æ›¼å“ˆé¡¿è·ç¦»
2. æ¬§å‡ é‡Œå¾—distance

# KNNï¼š

determine distance function

get the k nearest points in train data, and using Majority vote to select the right label.

The training error rate must be 0.

if k=even ,and encounter ties(with # of labels equal, majority vote does not work), consider change distance function/count another point/select the nearest distance.

feature scale matters!

if k Is very small,risk of overfitting.

when k becomes larger,decision boundary will become smooth.

if k is very big, underfitting.



Model Selection:



decision tree:

model:set of all possible decision trees

parameter: structure of a specific decision tree

learning algorithm: how to select the splitting parameter

hyperparameter:learning sl not decide but the tunable aspects of thhe model: depth



knn:

model:

parameter: no

learning algorithm: no

hyperparameter:k



perception has no hyperparameter.

cross-validation:

N-fold: seperate data set into N folds and every time estimate the error on leave out one fold by training  N-1 folds.



train-original=[train-subset]+[validation],pick the best hyperparameters give the lowest erro on[validation] and use it on {train-original} later.



hyperparameter optimization:

- grid search

  sample points(æŒ‰ç…§å›ºå®šé—´éš”è¸©ç‚¹ï¼Œæ‰€ä»¥æœ‰å¯èƒ½ä¼šè·³è¿‡æœ€ä¼˜è§£)

â€‹	consider all combinational cases

- random searchï¼ˆ recomended

  given time and randomly combine all hp(å› ä¸ºå¯ä»¥é€‰åˆ°æ›´å¤šçš„å–å€¼)





# Perceptionï¼š

1. å¯¹äºçº¿æ€§å¯åˆ†

![image-20250227132324081](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250227132324081.png)

![image-20250227133553638](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250227133553638.png)

å½“æ•°æ®é›†é‡Œå«æœ‰ä¸€äº›é”™è¯¯çš„exampleï¼ŒPerception will overfit

decision boundary should be linear

margin:The margin ğ›¾ for a dataset D is the greatest possible distance between a linear separator and the closest data point in Dtothat linear separator.

for linearly separable data,  perceptron algorithm  will converge in a finite steps..

Perception mistake bound:

![image-20250227141522171](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250227141522171.png)

xç»´æ•°ä¸å½±å“ï¼Œæ•´ä½“æ”¾å¤§nå€ä¹Ÿä¸å½±å“ã€‚ä¸­é—´marginè¶Šå¤§ï¼Œé‚£ä¹ˆ...

![image-20250304132310986](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250304132310986.png)

2. çº¿æ€§ä¸å¯åˆ†

   - kernal

     

     ![image-20250304140227778](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250304140227778.png)

     ![image-20250306133518841](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250306133518841.png)

     é¦–å…ˆå¯ä»¥æŠŠwè¡¨ç¤ºæˆï¼ˆæ¯æ¬¡æ›´æ–°wéƒ½æ˜¯+ã€-xï¼‰![image-20250306135917018](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250306135917018.png)

     

     ![image-20250304140314032](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250304140314032.png)

     æ˜ å°„åˆ°é«˜ç»´ç©ºé—´è®©å®ƒçº¿æ€§å¯åˆ†

     ä»€ä¹ˆæ—¶å€™èƒ½ç”¨kernalï¼š

     ![image-20250306133222533](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250306133222533.png)
     
     æ€§è´¨ï¼š
     
     1. å¯¹ç§°çŸ©é˜µ
     
     2. åŠæ­£å®šï¼š![image-20250304140840164](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250304140840164.png)
     
     3. ![image-20250304140905619](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250304140905619.png)
     
     4. ![image-20250304140918849](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250304140918849.png)
     
        

# Support Vector Machines

ä¼˜åŒ–ï¼š



ç›®çš„ï¼šæ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜å¹³é¢æœ€å¤§åŒ–ç±»åˆ«è¾¹ç•Œï¼ˆmarginï¼‰

1. çº¿æ€§å¯åˆ†

   æ–¹æ³•ï¼š

   - è®¾ç½®wä¸ºå†³ç­–è¾¹ç•Œçš„æ³•å‘é‡ï¼Œæ¨¡é•¿è®¾ç½®ä¸º1ï¼Œé‚£ä¹ˆç‚¹åˆ°ç›´çº¿è·ç¦»å°±æ˜¯|w.x|
   - ç”±ä¸Šæ–‡ï¼Œmarginè¶Šå¤§ï¼Œè¯•é”™æˆæœ¬è¶Šå°ï¼Œäºæ˜¯æˆ‘ä»¬éœ€è¦æ‰¾ä¸€ä¸ªæœ€å¤§çš„marginè®©æ‰€æœ‰xåˆ°ç›´çº¿çš„è·ç¦»éƒ½æ¯”ä»–å¤§ã€‚
   - ![image-20250304145927645](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250304145927645.png)

   reformulateï¼ŒåŸå› ï¼šç”±äº||w||^2ä¸æ˜¯ä¸€ä¸ªå‡¸å‡½æ•°ï¼Œä¸å¥½æ±‚ä¼˜åŒ–

   è½¬æ¢åçš„é—®é¢˜ï¼š![image-20250304150020828](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250304150020828.png)

2. ä¸æ˜¯çº¿æ€§å¯åˆ†

   æ¾å¼›å˜é‡ï¼š![image-20250304150218043](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250304150218043.png)
   
   è½¬æ¢ä¸ºå¯¹å¶é—®é¢˜ï¼Œåªå«ç‚¹ç§¯ï¼Œä½¿ç”¨kernalï¼š
   
     å› ä¸ºæ¾å¼›å˜é‡æ˜¯éè´Ÿçš„ï¼Œå› æ­¤æœ€ç»ˆçš„ç»“æœæ˜¯è¦æ±‚é—´éš”å¯ä»¥æ¯”1å°ã€‚ä½†æ˜¯å½“æŸäº›ç‚¹å‡ºç°è¿™ç§é—´éš”æ¯”1å°çš„æƒ…å†µæ—¶ï¼ˆè¿™äº›ç‚¹ä¹Ÿå«ç¦»ç¾¤ç‚¹ï¼‰ï¼Œæ„å‘³ç€æˆ‘ä»¬æ”¾å¼ƒäº†å¯¹è¿™äº›ç‚¹çš„ç²¾ç¡®åˆ†ç±»ï¼Œè€Œè¿™å¯¹æˆ‘ä»¬çš„åˆ†ç±»å™¨æ¥è¯´æ˜¯ç§æŸå¤±ã€‚æ‰€ä»¥è¦æ›´æ­£æŸå¤±å‡½æ•°
   
   å¦‚ä½•ä½¿ç”¨kernalï¼š
   
   ![	`](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250306133744467.png)
   
   å¯ä¾›é€‰æ‹©çš„kernalå‡½æ•°ï¼š![image-20250412191610421](assets/image-20250412191610421.png)
   
   å¯¹äºrbfï¼š
   
   - **`gamma` å¤§ï¼ˆå¦‚ `gamma=10`ï¼‰**ï¼šæ ¸å‡½æ•°è¡°å‡å¿«ï¼Œæ¨¡å‹æ›´å…³æ³¨é‚»è¿‘æ ·æœ¬ï¼Œæ˜“è¿‡æ‹Ÿåˆï¼ˆå¤æ‚è¾¹ç•Œï¼‰ã€‚
   - **`gamma` å°ï¼ˆå¦‚ `gamma=0.01`ï¼‰**ï¼šæ ¸å‡½æ•°è¡°å‡æ…¢ï¼Œå†³ç­–è¾¹ç•Œå¹³æ»‘ï¼Œæ˜“æ¬ æ‹Ÿåˆã€‚
   
   æŸå¤±å‡½æ•°ï¼š![image-20250324214219455](assets/image-20250324214219455.png)
   
   ![image-20250324214304264](assets/image-20250324214304264.png)

# Linear Regression

residuals: the vertical distance from y^ and y

Stochastic Gradient  Descentï¼š

![image-20250313141906841](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250313141906841.png)

è®¡ç®—çš„æ˜¯æ•´ä¸ªdatasetå¯¹Jçš„å€’æ•°ã€‚

![image-20250313141658656](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250313141658656.png)

SGDï¼šæ˜¯åªçœ‹sampleçš„é‚£ä¸€ä¸ªdata pointå¯¹Jçš„å¯¼æ•°ã€‚

![image-20250313141712665](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250313141712665.png)

Sæœ‰æ›´å¤šæ›´æ–°å‚æ•°çš„æœºä¼šï¼Œåœ¨å‰æœŸèƒ½å¤Ÿæ”¶æ•›åœ°æ›´å¿«å¹¶ä¸”æ—¶å€™æ•°æ®é‡å¤§çš„è®­ç»ƒé›†ã€‚

![image-20250313142150537](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250313142150537.png)

æ­£åˆ™åŒ–ï¼š![image-20250324192742565](assets/image-20250324192742565.png)

# MLE\MAP:

![image-20250318135845464](assets/image-20250318135845464.png)

MLE: Choose theta that maximizes the probability of observed data

![image-20250318135817397](assets/image-20250318135817397.png)

![image-20250318135926521](assets/image-20250318135926521.png)

![image-20250318140001461](assets/image-20250318140001461.png)

For Gaussian func

![image-20250318140029159](assets/image-20250318140029159.png)

map: Choose theta that maximizes the posterier probability.

![image-20250318141023031](assets/image-20250318141023031.png)

Conjugate:

![image-20250318141900502](assets/image-20250318141900502.png)

coin flippng:Binomial distribution. 

å½“sampleå¤Ÿå¤šï¼Œé‚£ä¹ˆå°±ä¼šå†²æ·¡priorçš„å½±å“ã€‚





MLEåœ¨Logistic regressionä¸­çš„åº”ç”¨ï¼š

æ ¹æ®ç»™çš„è®­ç»ƒé›†ï¼Œæ‰¾åˆ°æœ€ä¼˜çš„wè®©è¿™ç§trainingçš„æ¨¡å¼çš„å‡ºç°æ¦‚ç‡æœ€å¤§åŒ–ã€‚

é‚£ä¹ˆæŸå¤±å‡½æ•°å¯ä»¥çœ‹æˆä¸Šé¢çš„å–ç¬¦å·ï¼Œæœ€å°åŒ–è¿™ä¸ªå°±å¯ä»¥ã€‚

![image-20250320132910387](assets/image-20250320132910387.png)

é€»è¾‘å›å½’çš„å†³ç­–è¾¹ç•Œæ˜¯

p(x|theta)=sigmoidï¼ˆwxï¼‰=a

aç”±bayes optimal classifierå†³å®šã€‚

Bayes Optimal Classifier

0/1 lossï¼šä¸å¯å¯¼ï¼Œä¸€èˆ¬ç”¨æ¥åšè¯„ä¼°ã€‚

Logisticsçš„losså¯å¯¼ï¼ˆlog-lossï¼‰ï¼Œå¯ä»¥åšæ¢¯åº¦ã€‚

![image-20250325132835926](assets/image-20250325132835926.png)

![image-20250325132843955](assets/image-20250325132843955.png)

![image-20250325132855192](assets/image-20250325132855192.png)

Model Performance Metrics

![image-20250325133021478](assets/image-20250325133021478-1742880622528-1.png)

![image-20250325133137956](assets/image-20250325133137956.png)

 **Accuracy** is useful for evaluating classification model when classes are balanced ( binary or  multi-class classification).  When classes in the dataset are highly imbalanced, meaning there is a significant disparity in  the number of instances between classes, accuracy can be misleading. 

Precisionï¼š![image-20250325133155551](assets/image-20250325133155551.png)

æ›´åŠ å…³æ³¨æ˜¯å¦åˆ†ç±»æ­£ç¡®äº†positiveçš„å†…å®¹,å³å¸Œæœ›åˆ¤æ–­ä¸ºæ­£æ ·æœ¬æ—¶å€™è¿™ä¸ªæ ·æœ¬çš„ç¡®æ˜¯æ­£æ ·æœ¬ã€‚egï¼šæ¨é€æ­£ç¡®äº†ç”¨æˆ·å–œæ¬¢çš„å†…å®¹ï¼Œå‡å°‘å°†ç”¨æˆ·è®¨åŒå†…å®¹æ¨é€æˆç”¨æˆ·å–œæ¬¢çš„ã€‚

Recallï¼š

![image-20250325133454570](assets/image-20250325133454570.png)

egï¼šä¸èƒ½æ”¾è¿‡é˜³æ€§ç—…ä¾‹ã€‚



Feature engineering

åŸæ¥çš„featureåœ¨åŸæ¥çš„ç©ºé—´æ²¡åŠæ³•æ‹Ÿåˆåšå›å½’ï¼Œé‚£ä¹ˆå¯ä»¥è€ƒè™‘ä½¿ç”¨ï¼š **Nonlinearbasis functions** allow linear models(e.g. Linear  Regression, Logistic Regression) to capture nonlinear  aspects of the original input

![image-20250325140023131](assets/image-20250325140023131.png)

å½“xå‡ç»´ä¹‹åï¼Œå®¹æ˜“å‡ºç°overfitï¼Œä½†æ˜¯ä¹Ÿå¯ä»¥é€šè¿‡å¢åŠ æ ·æœ¬é‡æ¥å‡å°‘ã€‚

![image-20250325140334235](assets/image-20250325140334235.png)

![image-20250325140345766](assets/image-20250325140345766.png)

è°ƒæ•´æ–¹æ³•ï¼šRegularizationï¼š

 why we should not regularize the bias termï¼š

- å¦‚æœå¯¹åç½®é¡¹è¿›è¡Œæ­£åˆ™åŒ–ï¼Œä¼˜åŒ–è¿‡ç¨‹ä¼šå€¾å‘äºå°† b*b* æ¨å‘é›¶ï¼ˆå°¤å…¶æ˜¯L2æ­£åˆ™åŒ–ï¼‰ã€‚è¿™ç›¸å½“äºå¼ºåˆ¶æ¨¡å‹å¿…é¡»é€šè¿‡åŸç‚¹ï¼ˆy=wx*y*=*w**x*ï¼‰ï¼Œ**é™åˆ¶äº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›**ã€‚
- è®¸å¤šæ•°æ®æœ¬èº«ä¸é€‚åˆâ€œé€šè¿‡åŸç‚¹â€çš„å‡è®¾ï¼ˆå¦‚æ•°æ®åˆ†å¸ƒçš„å®é™…æˆªè·éé›¶ï¼‰ï¼Œå¼ºåˆ¶ b*b* å˜å°ä¼šå¯¼è‡´æ¨¡å‹éœ€è¦æ‰­æ›²æƒé‡ w*w* æ¥è¡¥å¿ï¼Œåè€Œé™ä½æ€§èƒ½ã€‚

å¦‚æœå¸Œæœ›wé‡Œå‡ºç°0ï¼Œä½¿ç”¨L1ï¼ŒL1lossä¸æ˜¯å‡¸å‡½æ•°ï¼Œæ²¡æœ‰closed solutionã€‚

L1ï¼šsubdifferentiable(not sifferentiable at 0)

å¦‚æœæƒ³è®©wæ›´sparseï¼Œç”¨L2ï¼ŒL2lossè¿˜æ˜¯æœ‰closed![image-20250325141148557](assets/image-20250325141148557.png)



# Neural Network

åˆ†ç±»é—®é¢˜ï¼šæœ€åä¸€å±‚ç”¨sigmoid

![image-20250327140121285](assets/image-20250327140121285.png)

å›å½’é—®é¢˜:æœ€åä¸€å±‚åšçº¿æ€§æ±‚å’Œ	

![image-20250327140131718](assets/image-20250327140131718.png)

ç¥ç»ç½‘ç»œæ²¡æœ‰å”¯ä¸€çš„æœ€ä¼˜è§£ã€‚

äºŒåˆ†ç±»æœ€åä¸€å±‚å°±æ˜¯1ä¸ªç¥ç»å…ƒï¼Œå¤šåˆ†ç±»é—®é¢˜æœ€åä¸€å±‚è¦æœ‰å¤šä¸ªç¥ç»å…ƒï¼Œ![image-20250327140938917](assets/image-20250327140938917.png)

![image-20250327141310430](assets/image-20250327141310430.png)

ç†è®ºä¸Šï¼Œä¸€å±‚hidden layerå¯ä»¥æ‹Ÿåˆå‡ºä»»ä½•å˜æ¢ã€‚

ç¥ç»ç½‘ç»œä¹Ÿéœ€è¦loss functionå’Œæ¢¯åº¦ä¸‹é™ã€‚

å‰å‘ä¼ æ’­ï¼š

é€šè¿‡æœ€åçš„ç»“æœè®¡ç®—lossã€‚

![image-20250401133325593](assets/image-20250401133325593.png)

åå‘ä¼ æ’­ï¼š

ç”¨é“¾å¼æ³•åˆ™æ›´æ–°wï¼Œtä»£è¡¨ç¬¬å‡ æ¬¡è¿­ä»£

![image-20250401133424598](assets/image-20250401133424598.png)

![image-20250401133713706](assets/image-20250401133713706.png)

![image-20250401133814345](assets/image-20250401133814345.png)

![image-20250401140216643](assets/image-20250401140216643.png)

è€ƒè™‘æ­£åˆ™åŒ–ï¼š

![image-20250401193556859](assets/image-20250401193556859.png)

![image-20250401223516288](assets/image-20250401223516288.png)

![image-20250401223527322](assets/image-20250401223527322.png)

wå¯¹lossçš„å½±å“ä»ä¸¤ä¸ªåˆ†æ”¯è¿›è¡Œã€‚

![image-20250401140136098](assets/image-20250401140136098.png)

å¯¹äºæœ€åä¸€å±‚ï¼Œåªå–æœ€å¤§çš„é‚£ä¸ª![image-20250401141010537](assets/image-20250401141010537.png)  

## å¯¼æ•°è®¡ç®—å…¬å¼ï¼š

![image-20250401142856198](assets/image-20250401142856198.png)

input shapeæ˜¯ä»€ä¹ˆï¼Œå¯¼æ•°shapeå°±æ˜¯ä»€ä¹ˆã€‚

![image-20250401142958813](assets/image-20250401142958813.png)

![image-20250401143218275](assets/image-20250401143218275.png)

ä¾‹é¢˜ï¼šï¼ˆæ³¨æ„ç»´åº¦ï¼‰

![image-20250401143552401](assets/image-20250401143552401.png)



# Metricï¼š

![image-20250412185305924](assets/image-20250412185305924.png)

![image-20250412185315448](assets/image-20250412185315448.png)

1. **precisionï¼ˆç²¾ç¡®ç‡ï¼‰**
   - è®¡ç®—å…¬å¼ï¼š`TP / (TP + FP)`
   - å«ä¹‰ï¼šæ¨¡å‹é¢„æµ‹ä¸ºæŸç±»çš„æ ·æœ¬ä¸­ï¼Œ**å®é™…å±äºè¯¥ç±»çš„æ¯”ä¾‹**ã€‚
   - ä¾‹å­ï¼šå¯¹äº `Ariel Sharon`ï¼Œç²¾ç¡®ç‡ 0.62 è¡¨ç¤ºæ¨¡å‹é¢„æµ‹ä¸º Ariel Sharon çš„æ ·æœ¬ä¸­ï¼Œ62% é¢„æµ‹æ­£ç¡®ã€‚
2. **recallï¼ˆå¬å›ç‡ï¼Œåˆç§°çµæ•åº¦ï¼‰**
   - è®¡ç®—å…¬å¼ï¼š`TP / (TP + FN)`
   - å«ä¹‰ï¼šå®é™…å±äºæŸç±»çš„æ ·æœ¬ä¸­ï¼Œ**è¢«æ¨¡å‹æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹**ã€‚
   - ä¾‹å­ï¼š`Ariel Sharon` çš„å¬å›ç‡ 0.72 è¡¨ç¤ºçœŸå®å±äºè¯¥ç±»çš„æ ·æœ¬ä¸­ï¼Œ72% è¢«æ¨¡å‹æ­£ç¡®è¯†åˆ«ã€‚
3. **f1-scoreï¼ˆF1åˆ†æ•°ï¼‰**
   - è®¡ç®—å…¬å¼ï¼š`2 * (precision * recall) / (precision + recall)`
   - å«ä¹‰ï¼šç²¾ç¡®ç‡å’Œå¬å›ç‡çš„**è°ƒå’Œå¹³å‡æ•°**ï¼Œç»¼åˆä¸¤è€…è¡¨ç°ï¼ˆå°¤å…¶é€‚ç”¨äºç±»åˆ«ä¸å¹³è¡¡æ•°æ®ï¼‰ã€‚
   - ä¾‹å­ï¼š`Ariel Sharon` çš„ F1 åˆ†æ•° 0.67 æ˜¯å…¶ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„å¹³è¡¡ç»“æœã€‚
4. **supportï¼ˆæ”¯æŒæ•°ï¼‰**
   - å«ä¹‰ï¼šæµ‹è¯•é›†ä¸­**å®é™…å±äºè¯¥ç±»çš„æ ·æœ¬æ•°é‡**ã€‚
   - ä¾‹å­ï¼š`George W Bush` çš„ support ä¸º 146ï¼Œè¡¨ç¤ºæµ‹è¯•é›†ä¸­æœ‰ 146 å¼ ä»–çš„ç…§ç‰‡ã€‚

# CNN

- **1. CNNçš„æ ¸å¿ƒæ€æƒ³**

  ![image-20250403143804525](assets/image-20250403143804525.png)

- **å±€éƒ¨æ„ŸçŸ¥**ï¼šä¸åƒå…¨è¿æ¥ç½‘ç»œé‚£æ ·æ¯ä¸ªç¥ç»å…ƒè¿æ¥æ‰€æœ‰è¾“å…¥ï¼ŒCNNçš„ç¥ç»å…ƒåªæ„Ÿå—è¾“å…¥çš„å±€éƒ¨åŒºåŸŸï¼ˆå¦‚3Ã—3åƒç´ å—ï¼‰ï¼Œæ›´é€‚åˆæ•æ‰å›¾åƒä¸­çš„å±€éƒ¨ç‰¹å¾ï¼ˆè¾¹ç¼˜ã€çº¹ç†ç­‰ï¼‰ã€‚

- **æƒé‡å…±äº«**ï¼šåŒä¸€å·ç§¯æ ¸ï¼ˆfilterï¼‰åœ¨å›¾åƒä¸Šæ»‘åŠ¨æ—¶å…±äº«å‚æ•°ï¼Œå¤§å¹…å‡å°‘å‚æ•°é‡ã€‚

- ![image-20250403140647160](assets/image-20250403140647160.png)

  åœ¨å·ç§¯å±‚ä¸­æ¯ä¸ªç¥ç»å…ƒè¿æ¥æ•°æ®çª—çš„æƒé‡æ˜¯å›ºå®šçš„ï¼Œæ¯ä¸ªç¥ç»å…ƒåªå…³æ³¨ä¸€ä¸ªç‰¹æ€§ã€‚ç¥ç»å…ƒå°±æ˜¯å›¾åƒå¤„ç†ä¸­çš„æ»¤æ³¢å™¨ï¼Œæ¯”å¦‚è¾¹ç¼˜æ£€æµ‹ä¸“ç”¨çš„Sobelæ»¤æ³¢å™¨ï¼Œå³å·ç§¯å±‚çš„æ¯ä¸ªæ»¤æ³¢å™¨éƒ½ä¼šæœ‰è‡ªå·±æ‰€å…³æ³¨ä¸€ä¸ªå›¾åƒç‰¹å¾ï¼Œæ¯”å¦‚å‚ç›´è¾¹ç¼˜ï¼Œæ°´å¹³è¾¹ç¼˜ï¼Œé¢œè‰²ï¼Œçº¹ç†ç­‰ç­‰ï¼Œè¿™äº›æ‰€æœ‰ç¥ç»å…ƒåŠ èµ·æ¥å°±å¥½æ¯”å°±æ˜¯æ•´å¼ å›¾åƒçš„ç‰¹å¾æå–å™¨é›†åˆã€‚

  ä¸€ç»„å›ºå®šçš„æƒé‡å’Œä¸åŒçª—å£å†…æ•°æ®åšå†…ç§¯: å·ç§¯

  

  ![image-20250403131501860](assets/image-20250403131501860.png)

  ![image-20250403131517646](assets/image-20250403131517646.png)

kernaléœ€è¦ä¿è¯å’ŒåŸå›¾çš„channelä¿æŒä¸€è‡´ï¼š

RGBä¸º3ï¼Œkernalå°±è¦3	

![image-20250403131724507](assets/image-20250403131724507.png)

è®¡ç®—outputsizeï¼š![image-20250403132705085](assets/image-20250403132705085.png)

â€‹	å¦‚æœæœ‰å¡«å……pï¼Œé‚£ä¹ˆå°±æ˜¯ï¼ˆN+2p-Fï¼‰ï¼ŒNæ˜¯åŸæ¥çš„ç»´åº¦ï¼ŒFæ˜¯kernalçš„ç»´åº¦ã€‚

> å› ä¸ºå·ç§¯æœ€åçš„å›¾åƒå¤§å°æ˜¯ç”±è¾ƒå°çš„ç»´åº¦å†³å®šçš„ï¼Œæ‰€ä»¥ä¼šæƒ³åˆ°åŠ å…¥padding



å¦‚æœkernalæ˜¯1\*1*nï¼Œé‚£ä¹ˆå¯ä»¥è°ƒæ•´nè¿›è¡Œå‡ç»´é™ç»´ã€‚

![image-20250403133438799](assets/image-20250403133438799.png)

åšå®Œconvä¹‹åï¼Œå› ä¸ºç›®å‰ä¸ºæ­¢éƒ½æ˜¯çº¿æ€§å˜åŒ–ï¼Œä¸ºäº†èƒ½å¤„ç†éçº¿æ€§æ“ä½œï¼Œå°±ç”¨æ¿€æ´»å‡½æ•°å°†çº¿æ€§æ‹Ÿåˆåˆ°éçº¿æ€§ï¼Œæ¯ä¸€ä¸ªç‚¹å¥—ä¸Šæ¿€æ´»å‡½æ•°ã€‚ä¹‹åå†åšæ± åŒ–ã€‚

- Pooling layerï¼š

  æ± åŒ–å±‚å¤¹åœ¨è¿ç»­çš„å·ç§¯å±‚ä¸­é—´ï¼Œ ç”¨äºå‹ç¼©æ•°æ®å’Œå‚æ•°çš„é‡ï¼Œå‡å°è¿‡æ‹Ÿåˆã€‚
  ç®€è€Œè¨€ä¹‹ï¼Œå¦‚**æœè¾“å…¥æ˜¯å›¾åƒçš„è¯ï¼Œé‚£ä¹ˆæ± åŒ–å±‚çš„æœ€ä¸»è¦ä½œç”¨å°±æ˜¯å‹ç¼©å›¾åƒã€‚**

  è¿™é‡Œå†å±•å¼€å™è¿°æ± åŒ–å±‚çš„å…·ä½“ä½œç”¨ï¼š

  1. **ç‰¹å¾ä¸å˜æ€§**ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬åœ¨å›¾åƒå¤„ç†ä¸­ç»å¸¸æåˆ°çš„ç‰¹å¾çš„å°ºåº¦ä¸å˜æ€§ï¼Œæ± åŒ–æ“ä½œå°±æ˜¯å›¾åƒçš„resizeï¼Œå¹³æ—¶ä¸€å¼ ç‹—çš„å›¾åƒè¢«ç¼©å°äº†ä¸€å€æˆ‘ä»¬è¿˜èƒ½è®¤å‡ºè¿™æ˜¯ä¸€å¼ ç‹—çš„ç…§ç‰‡ï¼Œè¿™è¯´æ˜è¿™å¼ å›¾åƒä¸­ä»ä¿ç•™ç€ç‹—æœ€é‡è¦çš„ç‰¹å¾ï¼Œæˆ‘ä»¬ä¸€çœ‹å°±èƒ½åˆ¤æ–­å›¾åƒä¸­ç”»çš„æ˜¯ä¸€åªç‹—ï¼Œå›¾åƒå‹ç¼©æ—¶å»æ‰çš„ä¿¡æ¯åªæ˜¯ä¸€äº›æ— å…³ç´§è¦çš„ä¿¡æ¯ï¼Œè€Œç•™ä¸‹çš„ä¿¡æ¯åˆ™æ˜¯å…·æœ‰å°ºåº¦ä¸å˜æ€§çš„ç‰¹å¾ï¼Œæ˜¯æœ€èƒ½è¡¨è¾¾å›¾åƒçš„ç‰¹å¾ã€‚

  2. **ç‰¹å¾é™ç»´**ï¼Œæˆ‘ä»¬çŸ¥é“ä¸€å¹…å›¾åƒå«æœ‰çš„ä¿¡æ¯æ˜¯å¾ˆå¤§çš„ï¼Œç‰¹å¾ä¹Ÿå¾ˆå¤šï¼Œä½†æ˜¯æœ‰äº›ä¿¡æ¯å¯¹äºæˆ‘ä»¬åšå›¾åƒä»»åŠ¡æ—¶æ²¡æœ‰å¤ªå¤šç”¨é€”æˆ–è€…æœ‰é‡å¤ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠè¿™ç±»å†—ä½™ä¿¡æ¯å»é™¤ï¼ŒæŠŠæœ€é‡è¦çš„ç‰¹å¾æŠ½å–å‡ºæ¥ï¼Œè¿™ä¹Ÿæ˜¯æ± åŒ–æ“ä½œçš„ä¸€å¤§ä½œç”¨ã€‚

  3. åœ¨ä¸€å®šç¨‹åº¦ä¸Š**é˜²æ­¢è¿‡æ‹Ÿåˆ**ï¼Œæ›´æ–¹ä¾¿ä¼˜åŒ–ã€‚

     max poolingï¼š![image-20250403141800286](assets/image-20250403141800286.png)







CNNçš„æ•°å­¦ç‰¹æ€§ï¼š

å›¾ç‰‡åšå¹³ç§»ï¼Œç‰¹å¾æå–ä¹Ÿä¼šå¹³ç§»ã€‚ä½†æ˜¯åšæ—‹è½¬å°±æ‰¾ä¸åˆ°ç‰¹å¾äº†ã€‚![image-20250403141649149](assets/image-20250403141649149.png)

å¯¹äºä¸€å±‚å·ç§¯å±‚ï¼Œå¯ä»¥æœ‰ç­‰å˜å½¢ï¼Œä½†æ˜¯åšäº†æ± åŒ–ä¹‹åå°±å¯¹æœªçŸ¥ä¸æ•æ„Ÿäº†ã€‚







## GoogleNetï¼š

![image-20250408133153742](assets/image-20250408133153742.png)

![image-20250408132659552](assets/image-20250408132659552.png)



![image-20250408132922759](assets/image-20250408132922759.png)å…ˆpoolå†åš1*1 convï¼Œä¸å…ˆåš11convå†åšpoolæœ€åæ‹¿åˆ°çš„feature mapæ˜¯ä¸€æ ·çš„ã€‚ä½†æ˜¯å…ˆåšpoolè¿ç®—ä¼šå°‘ä¸€ç‚¹ã€‚

**æ¢¯åº¦æ¶ˆå¤±**ï¼šå½“ç½‘ç»œå¾ˆæ·±çš„æ—¶å€™ï¼Œgradientä¼šéå¸¸å°ï¼Œè¿™æ—¶å€™å‡ ä¹å°±æ²¡æœ‰æ›´æ–°ã€‚é“¾å¼æ±‚å¯¼æ³•åˆ™ï¼Œå¯¼è‡´æµ…å±‚çš„weightæ˜¯ç”±æ·±å±‚çš„weightè¿ä¹˜ï¼Œå› ä¸ºè¿™é‡Œwåœ¨0åˆ°1ï¼Œæ‰€ä»¥ä¸æ–­è¿ä¹˜åªä¼šè¶Šæ¥è¶Šå°ã€‚

**æ¢¯åº¦çˆ†ç‚¸**ï¼šgradientå˜å¾—è¶Šæ¥è¶Šå¤§ï¼Œå› ä¸ºwå¤§äº1ã€‚

googleçš„è§£å†³ï¼š![image-20250408134036469](assets/image-20250408134036469.png)

åœ¨æµ…å±‚ç½‘ç»œå°±è¿æ¥ä¸€ä¸ªè¾“å‡ºã€‚





ResNetï¼š

![image-20250408140250779](assets/image-20250408140250779.png)

DenseNetï¼š

![image-20250408140318402](assets/image-20250408140318402.png)

# Semantic Segmentation 

loss function:

ç±»ä¼¼å‰é¢çš„

![image-20250408143316014](assets/image-20250408143316014.png)

![image-20250408143340401](assets/image-20250408143340401.png)



# Recommandation:

**Content filteringï¼š**



![image-20250422132201037](assets/image-20250422132201037.png)

**Collaborative Filtering:**

å¯ä»¥ä¸éœ€è¦äº§å“ä¿¡æ¯å’Œuserä¿¡æ¯ï¼Œåªæ˜¯åŸºäºuser item matrix

åªéœ€è¦çŸ©é˜µ

Commoninsight:personaltastesarecorrelatedâ€“ IfAlice andBobbothlike XandAlicelikes Ythen Bobismorelikely to  like Yâ€“ especially (perhaps)if BobknowsAlice

1. neighborhood methods:

â€‹	![image-20250422132018830](assets/image-20250422132018830.png)

2. latent factor method

   ä¸éœ€è¦side infomation

   ![image-20250422132103045](assets/image-20250422132103045.png)

   çŸ©é˜µåˆ†è§£ï¼š

   ![image-20250422133110103](assets/image-20250422133110103.png)

   ![image-20250422140607859](assets/image-20250422140607859.png)

   é€šè¿‡å­¦ä¹ trainï¼Œå¾—åˆ°UVæˆç»©æ¥é¢„æµ‹ç©ºç™½éƒ¨åˆ†ã€‚

   ![image-20250422132505242](assets/image-20250422132505242.png)

   Historyï¼šæ€€æ—§çš„äºº

   roï¼šæµªæ¼«çš„äºº

   åˆ—æ˜¯ä¸åŒçš„ç”µå½±ã€‚

   Eæ˜¯è¦æ±‚çš„çŸ©é˜µå’ŒUä¹˜VTçš„ç›¸å·®çŸ©é˜µ

   1. unconstarinedï¼š

      low-rank MFï¼š

      ![image-20250422133230557](assets/image-20250422133230557.png)

      ![image-20250422133314222](assets/image-20250422133314222.png)

      â€‹	

      éœ€è¦ä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°æ˜¯
      $$
      E=R-UV^T\\
      Z={(i,j):R_{i,j}known}\\
      \frac{1}{2}||E||^2=\frac{1}{2}\sum_{i,j\in{Z}}(R_{i,j}-U{i,.}V_{.,j}^T)^2
      $$
      å‚æ•°æ›´æ–°ï¼š

      ![image-20250422134039269](assets/image-20250422134039269.png)

      ![image-20250422134202715](assets/image-20250422134202715.png)

      ![image-20250422141008877](assets/image-20250422141008877.png)

      å¦‚æœè¯´çŸ¥é“user çš„åçˆ±![image-20250422134436859](assets/image-20250422134436859.png)

      é‚£ä¹ˆå¯ä»¥é€šè¿‡åŠ ä¸Šbias Oå’ŒP

   2. SVDï¼š

      ![image-20250422141027899](assets/image-20250422141027899.png)

   3. Nonnegative Matrix Facorizationï¼š

   

   



# AdaBoost

Def:a weak learner is onethatreturns a hypothesisthatis not much better than random guessing 

Def:a strong learner is one that returns a hypothesis of arbitrarily  low error

[AdaBoost](https://so.csdn.net/so/search?q=AdaBoost&spm=1001.2101.3001.7020)æ˜¯å…¸å‹çš„Boostingç®—æ³•ã€‚

[Boostingç®—æ³•](https://so.csdn.net/so/search?q=Boostingç®—æ³•&spm=1001.2101.3001.7020)æ˜¯å°†â€œå¼±å­¦ä¹ ç®—æ³•â€œæå‡ä¸ºâ€œå¼ºå­¦ä¹ ç®—æ³•â€çš„è¿‡ç¨‹ï¼Œä¸»è¦æ€æƒ³æ˜¯â€œä¸‰ä¸ªè‡­çš®åŒ é¡¶ä¸ªè¯¸è‘›äº®â€ã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œæ‰¾åˆ°å¼±å­¦ä¹ ç®—æ³•è¦ç›¸å¯¹å®¹æ˜“ä¸€äº›ï¼Œç„¶åé€šè¿‡åå¤å­¦ä¹ å¾—åˆ°ä¸€ç³»åˆ—å¼±[åˆ†ç±»å™¨](https://so.csdn.net/so/search?q=åˆ†ç±»å™¨&spm=1001.2101.3001.7020)ï¼Œç»„åˆè¿™äº›å¼±åˆ†ç±»å™¨å¾—åˆ°ä¸€ä¸ªå¼ºåˆ†ç±»å™¨ã€‚

**1. åŠ æ³•æ¨¡å‹**

åŠ æ³•æ¨¡å‹å°±æ˜¯æˆ‘ä»¬æœ€ç»ˆçš„å¼ºåˆ†ç±»å™¨æ˜¯è‹¥å¹²ä¸ªå¼±åˆ†ç±»å™¨åŠ æƒå¹³å‡è€Œå¾—åˆ°çš„ï¼ˆå¼±åˆ†ç±»å™¨çº¿æ€§ç›¸åŠ è€Œæˆï¼‰ã€‚

**2. å‰å‘åˆ†æ­¥ç®—æ³•**

å‰å‘åˆ†æ­¥å°±æ˜¯æˆ‘ä»¬åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œä¸‹ä¸€è½®è¿­ä»£äº§ç”Ÿçš„åˆ†ç±»å™¨æ˜¯åœ¨ä¸Šä¸€è½®çš„åŸºç¡€ä¸Šè®­ç»ƒå¾—æ¥çš„ã€‚

æˆ‘ä»¬çš„ç®—æ³•æ˜¯é€šè¿‡ä¸€è½®è½®çš„å¼±å­¦ä¹ å™¨å­¦ä¹ ï¼Œåˆ©ç”¨å‰ä¸€ä¸ªå¼±å­¦ä¹ å™¨çš„ç»“æœå’Œå½“å‰å¼±å­¦ä¹ å™¨æ¥æ›´æ–°å½“å‰çš„å¼ºå­¦ä¹ å™¨çš„æ¨¡å‹ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼š

ç¬¬*k*âˆ’1è½®çš„å¼ºå­¦ä¹ å™¨ä¸º:
$$
f _
k
â€‹
 (x)=f _{kâˆ’1
}

â€‹
 (x)+Î± _
k
â€‹
 G_ 
k
â€‹
 (x)
$$
Adaboost:

è¿™é‡Œçš„é›†åˆèµ·æ¥çš„ç­–ç•¥æ˜¯é€šè¿‡æé«˜å‰ä¸€è½®åˆ†ç±»å™¨åˆ†ç±»é”™è¯¯çš„æ ·æœ¬çš„æƒå€¼ï¼Œé™ä½åˆ†ç±»åˆ†ç±»æ­£ç¡®çš„æ ·æœ¬æƒå€¼ï¼Œå¯¹äºé‚£äº›æ²¡æœ‰æœ¬åˆ†ç±»æ­£ç¡®çš„æ ·æœ¬ä¼šå¾—åˆ°åé¢åˆ†ç±»å™¨æ›´å¤šçš„å…³æ³¨ã€‚ç„¶åå¯ä»¥äº§ç”Ÿå¾ˆå¤šçš„å¼±åˆ†ç±»å™¨ï¼Œé€šè¿‡å¤šæ•°åŠ æƒæŠ•ç¥¨ç»„åˆè¿™äº›å¼±åˆ†ç±»å™¨ï¼ŒåŠ å¤§è¯¯å·®ç‡å°çš„åˆ†ç±»å™¨ï¼Œå‡å°‘è¯¯å·®ç‡å¤§çš„åˆ†ç±»å™¨ï¼Œä½¿å…¶åœ¨è¡¨å†³ä¸­èµ·åˆ°è¾ƒå°‘çš„ä½œç”¨ã€‚

![image-20250429131552694](assets/image-20250429131552694.png)

1ï¼‰åˆå§‹åŒ–è®­ç»ƒæ ·æœ¬çš„æƒå€¼åˆ†å¸ƒï¼Œæ¯ä¸ªæ ·æœ¬å…·æœ‰ç›¸åŒæƒé‡ï¼›

ï¼ˆ2ï¼‰è®­ç»ƒå¼±åˆ†ç±»å™¨ï¼Œå¦‚æœæ ·æœ¬åˆ†ç±»æ­£ç¡®ï¼Œåˆ™åœ¨æ„é€ ä¸‹ä¸€ä¸ªè®­ç»ƒé›†ä¸­ï¼Œå®ƒçš„æƒå€¼å°±ä¼šè¢«é™ä½ï¼›åä¹‹æé«˜ã€‚ç”¨æ›´æ–°è¿‡çš„æ ·æœ¬é›†å»è®­ç»ƒä¸‹ä¸€ä¸ªåˆ†ç±»å™¨ï¼›

ï¼ˆ3ï¼‰å°†æ‰€æœ‰å¼±åˆ†ç±»ç»„åˆæˆå¼ºåˆ†ç±»å™¨ï¼Œå„ä¸ªå¼±åˆ†ç±»å™¨çš„è®­ç»ƒè¿‡ç¨‹ç»“æŸåï¼ŒåŠ å¤§åˆ†ç±»è¯¯å·®ç‡å°çš„å¼±åˆ†ç±»å™¨çš„æƒé‡ï¼Œé™ä½åˆ†ç±»è¯¯å·®ç‡å¤§çš„å¼±åˆ†ç±»å™¨çš„æƒé‡ã€‚
$$
T={(x 
1
â€‹
 ,y 
1
â€‹
 ),(x 
2
â€‹
 ,y 
2
â€‹
 ),...,(x 
m
â€‹
 ,y 
m
â€‹
 )}\\
 D(k)=(w 
k1
â€‹
 ,w 
k2
â€‹
 ,...,w 
km
â€‹
 );w 
1i
â€‹
 = 
m
1
â€‹
 ;i=1,2,...,m\\
$$
![image-20250429131916956](assets/image-20250429131916956.png)

å½“è¯¯å·®è¶Šå¤§ï¼Œakè¶Šå°ã€‚è¿™ä¸ªåˆ†ç±»å™¨æ‰€å çš„æƒé‡å°±è¶Šå°ã€‚

![image-20250429132027752](assets/image-20250429132027752.png)

![image-20250429132128203](assets/image-20250429132128203.png)

![image-20250429132321361](assets/image-20250429132321361.png)æ³¨æ„åˆ°åˆå§‹dataçš„æƒé‡æ˜¯å‡åŒ€åˆ†å¸ƒ

ä¸ä¼šé€ æˆoverfitinï¼šå› ä¸ºä¸æ˜¯maximize accuè€Œæ˜¯åœ¨maxmize marginï¼š![image-20250429132719880](assets/image-20250429132719880.png)

![image-20250429134257908](assets/image-20250429134257908.png)

å› ä¸ºweightæ¯æ¬¡æ›´æ–°éƒ½æ˜¯æœ‰normalizeçš„æ‰€ä»¥è¯¯å·®çš„correctå’ŒwrongåŠ å’Œå°±æ˜¯1.

**Adaboostçš„ä¼˜ç‚¹ï¼š**

1ï¼‰Adaboostä½œä¸ºåˆ†ç±»å™¨æ—¶ï¼Œåˆ†ç±»ç²¾åº¦å¾ˆé«˜ï¼›

2ï¼‰åœ¨Adaboostçš„æ¡†æ¶ä¸‹ï¼Œå¯ä»¥ä½¿ç”¨å„ç§å›å½’åˆ†ç±»æ¨¡å‹æ¥æ„å»ºå¼±å­¦ä¹ å™¨ï¼Œéå¸¸çµæ´»ï¼›

3ï¼‰ä½œä¸ºç®€å•çš„äºŒå…ƒåˆ†ç±»å™¨æ—¶ï¼Œæ„é€ ç®€å•ï¼Œå®¹æ˜“å®æ–½ï¼Œç»“æœå¯ç†è§£ï¼›

4ï¼‰ä¸å®¹æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆã€‚

**Adaboostçš„ç¼ºç‚¹ï¼š**

1ï¼‰å¯¹å¼‚å¸¸æ ·æœ¬æ•æ„Ÿï¼Œå¼‚å¸¸æ ·æœ¬åœ¨è¿­ä»£ä¸­å¯èƒ½ä¼šè·å¾—è¾ƒé«˜çš„æƒé‡ï¼Œå½±å“æœ€ç»ˆçš„å¼ºå­¦ä¹ å™¨çš„é¢„æµ‹å‡†ç¡®æ€§ï¼›

2ï¼‰è®­ç»ƒæ—¶é—´è¿‡é•¿ï¼Œæ¯æ¬¡ä¸€ä¸ªåˆ†ç±»å™¨éƒ½è¦ç”¨å…¨éƒ¨æ ·æœ¬å­¦ä¹ ï¼Œå¯¹äºå¼±åˆ†ç±»å™¨å­¦ä¹ æ¥è®²ï¼Œæ—¶é—´åŠé€Ÿåº¦ä¸Šå½±å“ä¸å¤§ï¼Œå¼ºåˆ†ç±»å™¨çš„å­¦ä¹ æ—¶é—´ä¼šå°±ä¼šæ¯”è¾ƒå¤§ã€‚

![image-20250429140826296](assets/image-20250429140826296.png)ä»çº¿æ€§ç®€å•æ¨¡å‹åˆ°éçº¿æ€§æ¨¡å‹ã€‚





# Bagging

éšæœºé€‰å–subset

1. (sample) bagging 

2.  feature bagging(aka. randomsubspacemethod) 

3. randomforests(whichcombinesamplebaggingandfeaturebaggingtotraina  â€œforestâ€ of decisiontrees)ï¼š

   å› ä¸ºDecision Tree å¾ˆå®¹æ˜“å—åˆ°æ•°æ®å˜åŒ–çš„å½±å“ã€‚

   ![image-20250429141811788](assets/image-20250429141811788-1745907492891-1.png)

   ![image-20250429142021146](assets/image-20250429142021146.png)å³ä½¿æ˜¯subsetæ ·æœ¬æ•°å’ŒåŸæ¥çš„trainsetçš„æ ·æœ¬æ•°ä¸€æ ·ï¼Œä¹Ÿä¼šå› ä¸ºé‡å¤é€‰å–äº†æ ·æœ¬æ•°èšç„¦äºä¸åŒçš„è¾“å…¥ç©ºé—´ã€‚

   ![image-20250429142207044](assets/image-20250429142207044.png)

   æ¯æ¬¡åˆ†æ”¯é€‰å–featureï¼Œéšæœºé€‰å–subsetä¸ªï¼Œå…¶ä¸­é€‰å‡ºæœ€ä¼˜çš„é‚£ä¸€ä¸ªï¼ˆmutual informationï¼‰

![image-20250429142320197](assets/image-20250429142320197-1745907801165-3.png)

ç”ŸæˆBä¸ªDecision treeã€‚

æ€ä¹ˆå»é€‰å–è¶…å‚æ•°Bï¼Œrouã€‚ç”¨validation setåšæµ‹è¯•ã€‚

è¿™é‡Œç›´æ¥æŠŠæ¯ä¸ªå†³ç­–æ ‘æ²¡æœ‰è®­ç»ƒè¿‡çš„sampleæ¥åšæµ‹è¯•ã€‚æ¯”cross valiå¥½çš„ä¸€ç‚¹æ˜¯ä¸éœ€è¦è®­ç»ƒå¤šä¸ªæ£®æ—ã€‚

![image-20250429143038114](assets/image-20250429143038114.png)



å¦‚æœå¤šä¸ªtreeé‡Œé¢‘ç¹ç”¨åˆ°äº†æŸä¸ªfeatureï¼Œæˆ–è€…å¤šä¸ªtreeç”¨äº†æŸä¸ªfeatureä¹‹åï¼Œå¹³å‡ä¸‹æ¥uncertaintyä¸‹é™çš„å¹³å‡å€¼æ˜¯å¤šå°‘ã€‚æˆ–è€…å»é™¤è¿™ä¸ªfeatureçœ‹çœ‹å¯¹performanceçš„å½±å“ã€‚

å®éªŒï¼šæ§åˆ¶å˜é‡ã€‚



# Guassian Mixture Models

**é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMï¼‰** æ˜¯ä¸€ç§æ¦‚ç‡æ¨¡å‹ï¼Œç”¨äºè¡¨ç¤ºç”±å¤šä¸ªé«˜æ–¯ï¼ˆæ­£æ€ï¼‰åˆ†å¸ƒç»„åˆè€Œæˆçš„æ•°æ®åˆ†å¸ƒã€‚å®ƒå‡è®¾æ•°æ®æ˜¯ç”± **K ä¸ªé«˜æ–¯åˆ†å¸ƒ** ä»¥ä¸€å®šæƒé‡æ··åˆç”Ÿæˆçš„ï¼Œå¸¸ç”¨äº **èšç±»ã€å¯†åº¦ä¼°è®¡ã€å¼‚å¸¸æ£€æµ‹** ç­‰ä»»åŠ¡ã€‚

çŸ¥é“æ˜¯ä»€ä¹ˆç±»åˆ«å°±å¯ä»¥åšMLE

![image-20250506140858335](assets/image-20250506140858335.png)



![image-20250506142255229](assets/image-20250506142255229.png)

![image-20250506142818910](assets/image-20250506142818910-1746512899436-1.png)

# PCA

â€‹	
